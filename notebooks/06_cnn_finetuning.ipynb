{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fc9wyyGloQwL"
   },
   "source": [
    "# Finetuning a ResNet\n",
    "\n",
    "Modern deep convnets tend to have tens (if not hundreds) of layers, with millions (if not tens of millions) of trainable parameters. More often than not several of these layers have skipped connections; the *ResNet* family of networks are an example. \n",
    "\n",
    "The flip side of having such deep network architectures is that to properly learn such networks, one requires *massive* amounts of training data. In most applications, access to such massive datasets simply isn't available; gathering and curating a dataset with a few hundred/thousand examples itself can be a challenge.\n",
    "\n",
    "What should one do in the ``small data'' setting? A possible solution:\n",
    "* start with a deep network architecture initialized with *pre-trained* weights, and\n",
    "* *fine-tune* the network weights on the (small) training dataset.\n",
    "\n",
    "In this demo we will see how to train a simple cat-vs-dog classifier using a very small training dataset of 60 images. The dataset is provided [here](https://github.com/chinmayhegde/dl-demos/blob/main/data.zip). You can unzip and save the dataset anywhere you like; I've saved it to my Google drive folder: `MyDrive\\data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "bGT3H4DjoO9n"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "qNHnEAckpqps"
   },
   "outputs": [],
   "source": [
    "\n",
    "# data transforms\n",
    "dset_transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                             [0.229, 0.224, 0.225])])\n",
    "\n",
    "\n",
    "# Use the image folder function to create datasets\n",
    "dsets = {x: datasets.ImageFolder(f\"./data/{x}\", dset_transform)\n",
    "         for x in ['train', 'val']}\n",
    "\n",
    "# create data loader\n",
    "dataloaders = {x: torch.utils.data.DataLoader(dsets[x], batch_size=16,\n",
    "                                              shuffle=(x == \"train\"))\n",
    "               for x in ['train', 'val']}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iYSEZtTDJUYV"
   },
   "source": [
    "# Loading a pre-trained ResNet model\n",
    "\n",
    "Let's load a ResNet34 model from `torchvision` and examine it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "tOYRfm1pBcoM"
   },
   "outputs": [],
   "source": [
    "# intialize model\n",
    "model = models.resnet34(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mVgCL8ZTtvTt",
    "outputId": "09f55e48-9227-4cbc-d857-0547a22c2304"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfWGLTlJLxzI"
   },
   "source": [
    "Hmm, lots of layers. Each `BasicBlock` is two or three conv layers with a skipped connection, with batch-norm layers thrown in for good measure. Several such residual blocks are pieced together, and in the end there is a dense layer with 1000 output neurons. This model has been trained on the well-known *ImageNet* dataset (which has over a million images with 1000 classes). As an aside, let's examine the number of trainable parameters in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jl9m-Z4EDFFW",
    "outputId": "e5be439e-7a37-44ff-cd51-275981c573b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21797672\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FdzbKTClM_Qv"
   },
   "source": [
    "Let us finetune this model for our cat-vs-dog classification problem. Since this is a binary classifier we will redefine the output (linear) layer to have 2 outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qkjny7j5BDRS",
    "outputId": "ac369f98-f12d-4141-ac0e-b71d796df3cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "512\n"
     ]
    }
   ],
   "source": [
    "num_ftrs = model.fc.in_features\n",
    "print(num_ftrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "nhnOEfZoDQS6"
   },
   "outputs": [],
   "source": [
    "model.fc = nn.Linear(num_ftrs, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jv86CyS3DVe8",
    "outputId": "2b5b294f-e026-4083-9d05-9e5294f39291"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (3): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (4): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (5): BasicBlock(\n",
      "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): BasicBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "    (2): BasicBlock(\n",
      "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TIDpqRLJOMaJ"
   },
   "source": [
    "Observe now that the basic ResNet34 backbone remains the same; only the output layer has changed. In fact, all of the weights (except the output layer) also have been retained.  \n",
    "\n",
    "Let's do a quick model evaluation to check if there are any errors thrown during prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bq72K2tuDn3h",
    "outputId": "55fb64bb-3092-47a1-ad94-13a21d0dc3d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5000)\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "corrects = 0\n",
    "for batch_idx, (inputs,labels) in enumerate(dataloaders['val'], 1):\n",
    "  with torch.set_grad_enabled(False):\n",
    "    outputs = model(inputs)\n",
    "    _, preds = torch.max(outputs,1)\n",
    "    \n",
    "  corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "print(corrects.float() / len(dataloaders['val'].dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI3eN9vcPEHb"
   },
   "source": [
    "As we can see, we get an accuracy of 50\\% on the test set -- which is exactly what we would expect since the weights of the output layer are random. \n",
    "\n",
    "We are now ready to start fine-tuning! The rest of the code below is boilerplate training; we see below that only a few epochs are enough to tune the weights to our training dataset.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UZ8n_358A6aY"
   },
   "outputs": [],
   "source": [
    "# define loss function, optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "save_loss = {'train':[], 'val':[]}\n",
    "save_acc = {'train':[], 'val':[]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wJHYjaYtrNHm",
    "outputId": "e970dd83-9647-4845-cdf0-673b57e70c5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:0 -- Phase:train -- Loss:0.79 -- Acc:48.33\n",
      "Epoch:0 -- Phase:val -- Loss:0.61 -- Acc:66.67\n",
      "Epoch:1 -- Phase:train -- Loss:0.42 -- Acc:90.00\n",
      "Epoch:1 -- Phase:val -- Loss:0.28 -- Acc:100.00\n",
      "Epoch:2 -- Phase:train -- Loss:0.22 -- Acc:96.67\n",
      "Epoch:2 -- Phase:val -- Loss:0.12 -- Acc:100.00\n",
      "Epoch:3 -- Phase:train -- Loss:0.08 -- Acc:100.00\n",
      "Epoch:3 -- Phase:val -- Loss:0.06 -- Acc:100.00\n",
      "Epoch:4 -- Phase:train -- Loss:0.06 -- Acc:100.00\n",
      "Epoch:4 -- Phase:val -- Loss:0.04 -- Acc:100.00\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "\n",
    "    # Each epoch has a training and validation phase\n",
    "    for phase in ['train', 'val']:\n",
    "        if phase == 'train':\n",
    "            model.train()  # Set model to training mode\n",
    "        else:\n",
    "            model.eval()   # Set model to evaluate mode\n",
    "\n",
    "        current_loss = 0.0\n",
    "        current_corrects = 0\n",
    "\n",
    "        for batch_idx, (inputs, labels) in enumerate(dataloaders[phase], 1):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Time to carry out the forward training poss\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                outputs = model(inputs)\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                loss = criterion(outputs, labels)\n",
    "\n",
    "                # backward + optimize only if in training phase\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            # We want variables to hold the loss/acc statistics\n",
    "            current_loss += loss.item() * inputs.size(0)\n",
    "            current_corrects += torch.sum(preds == labels.data)\n",
    "        # saving variable for plottin\n",
    "        save_loss[phase] += [current_loss / len(dataloaders[phase].dataset)]\n",
    "        save_acc[phase] += [current_corrects.float() / len(dataloaders[phase].dataset)]\n",
    "\n",
    "        # pretty print\n",
    "        print(f\"Epoch:{epoch} -- Phase:{phase} -- Loss:{save_loss[phase][-1]:.2f} -- Acc:{save_acc[phase][-1]*100:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "id": "JGgbCwdTuy1h",
    "outputId": "75c79f5d-f52b-4109-9525-0232417c38c4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(save_acc['train'])\n",
    "plt.plot(save_acc['val'])\n",
    "plt.legend([\"train\", \"test\"])\n",
    "plt.title(\"Accuracy\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h1__s46hPeUg"
   },
   "source": [
    "There we go! That took only 4 epochs of finetuning.\n",
    "\n",
    "This was a very small dataset (of only 60 training images) so it is not that surprising that we were able to fit the data so easily. Try training your own classifier with a slightly larger set of data points, and see if you can get similar results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "demo5-test.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
